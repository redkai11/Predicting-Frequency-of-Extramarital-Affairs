---
title: "**Predicting Frequency of Extramarital Affairs**"
author: "Sarah Li (#60136959), Jun Won (Lakon) Park (#79453940)"
output: 
  bookdown::pdf_document2:
    fig_caption: yes
    includes:
      in_header: preamble.tex
    number_sections: true
    toc: FALSE
header-includes:
  \usepackage{caption}
  \usepackage{float}
  \floatplacement{figure}{H}
  \captionsetup[table]{labelformat=empty}
---

What influences married individuals to become involved in affairs? There is speculation about what influences how likely someone will cheat on their spouse, and we would like to confirm speculations with real data. With this project, we are aiming to predict whether an individual is involved in extramarital affairs. If they are involved, we would like to also predict the frequency of involvement. In order to build our predictive model, we will also explore how each predictor influences the chances of infidelity in a marriage.

# Introduction

## Data {-}

The "Affairs" data is from a survey conducted by Psychology Today in 1969. The response variable is **affairs**, representing how often the individual engaged in extramarital sexual involvements in the past year. 
There are 6 ordinal, and 2 categorical predictor variables. The survey conducted collected information in ranges for simplicity. 

```{r include = FALSE}
knitr::opts_chunk$set(fig.cap = " ")
```


```{r 2, include = FALSE}
data <- data("Affairs", package="AER")
n <- nrow(data) # 601 observations
p_total <- ncol(data) - 1 # 8 predictors
```

\begin{tabular}{ c|c } 
\hline
\textbf{Value} & \textbf{Frequency of affairs}\\
\hline
\hline
0 & None \\  
1 & Once \\
2 & Twice  \\ 
3 & 3 times \\
7 & 4-10 times \\ 
12 & Monthly or more often \\  
\hline
\end{tabular}


**Predictor variables**: 

- Sex (0 = female, 1 = male)

- Children (0 = no, 1 = yes)

- Age (17.5 = under 20, 22 = 20–24, 27 = 25–29, 32 = 30–34, 37 = 35–39, 42 = 40–44, 47 = 45–49, 52 = 50–54, 57 = 55 or over)

- Number of years married (0.125 = 3 months or less, 0.417 = 4–6 months, 0.75 = 6 months–1 year, 1.5 = 1–2 years, 4 = 3–5 years, 7 = 6–8 years, 10 = 9–11 years, 15 = 12 or more years)

- How religious (5 = very, 4 = somewhat, 3 = slightly, 2 = not at all, 1 = anti)

- Level of education (9 = grade school, 12 = high school graduate, 14 = some college, 16 = college graduate, 17 = some graduate work, 18 = master's degree, 20 = Ph.D., M.D., or other advanced degree)

- Occupation rating (1-7 according to [**Hollingshead classification scale**](https://dictionary.fitbir.nih.gov/portal/publicData/dataElementAction!view.action?dataElementName=HollingsheadJobClassCat&publicArea=true), reverse numbered)

- Marriage rating (5 = very happy, 4 = happier than average, 3 = average, 2 = somewhat unhappy, 1 = very unhappy)

## Areas of Interest {-}

Many may assume that marriage stability, or "sunk-cost" of a marriage decreases the likelihood of affairs. In that sense, it is worth investigating whether years married, having children, or marriage satisfaction are influential. Moreover, variables which may not obviously contribute to infidelity, such as religiousness and socioeconomic status (contributed to by education level and occupation rating), might have some influence. 

In order to find out which predictors play the biggest role in determining if a married individual is involved in an affair, we would like to explore association between variables and determine if we should use those variables with the strongest correlation in our predictive model.  

Finally, we are interested in creating a model that can predict if an individual has been involved in extramarital affairs using the variables found to contribute to infidelity. To build on this, we will also try to predict the frequency of affairs.

<!-- Include some foreshadowing of results once we have results -->

# Exploratory Data Analysis

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gridExtra)
library(caret)
library(StatMatch)
library(corrplot)
library(randomForest)
library(smotefamily)
library(kableExtra)
```

In order to investigate what influences cheating in a marriage, ignoring frequency, we define \textbf{cheat} as a binary variable based on the \textbf{affairs} column.

```{r}
data("Affairs", package="AER")
df <- Affairs
rownames(df) <- NULL
# cheat = 0 if frequency of affairs = 0
# cheat = 1 if frequency of affairs > 0
df$cheat <- ifelse(df$affairs > 0, 1, 0)
df$cheat <- factor(df$cheat)

table(df$affairs)

```

```{r, echo=FALSE, fig.height = 4, fig.cap="Cheat = 1 shows the number of females and males in the group of respondents who have cheated within a year before taking the survey. Cheat = 0 shows the number of those who did not."}
ggplot(data = df, aes(x=cheat, fill = gender)) +
  geom_bar()

wilcox.test(as.numeric(df$cheat)~df$gender, alternative="less")
```

\begin{itemize}
\item From Figure 1, the proportion of individuals involved in affairs by gender seems to be equal which suggests no apparent relationship between gender and affairs.
\item This is contradictory to many numerous sample surveys\footnote{\href{https://ifstudies.org/blog/who-cheats-more-the-demographics-of-cheating-in-america}{Reference: Summary of results from General Social Survey}} that say more men cheat than women.
\item The Mann–Whitney U test\footnote{\href{https://www.sheffield.ac.uk/polopoly_fs/1.885207!/file/99_Mann_Whitney_U_Test.pdf}{Reference: Mann-Whiteney U test in R}} (Wilcoxon rank sum test with continuity correction) can be conducted by treating \textbf{cheat} as an ordinal variable, since we are not interested at frequency at this point, to confirm if there is a difference between males and females. The alternative used is "less" because we might guess that women cheat less than men. The p-value is found to be greater than 0.1, so the difference between genders is insignificant.
\end{itemize}

```{r echo=FALSE, fig.cap="(Left) The proportion of cheating individuals distributed over age. (Right) Compares the distribution of ages in the cheating group and non-cheating group."}
p2 <- ggplot(data = df, aes(x=age, fill = factor(cheat))) +
  geom_histogram(color="#e9ecef", alpha=0.6, position = 'identity', binwidth = 5) +
  labs(fill = "cheat")

p2.1 <- ggplot(data = df, aes(x=cheat, y = age)) +
  geom_boxplot()

grid.arrange(p2,p2.1, ncol = 2)
```

```{r echo=FALSE, fig.height = 4, fig.cap="Distribution of individuals involved in affairs over all ages of respondents."}
p2.2 <- ggplot(data = df, aes(x = age, fill = factor(cheat))) +
  geom_histogram(color="#e9ecef", alpha=0.6, position = 'identity', binwidth = 5)
p2.2
```

```{r}
summary(df$age)
summary(df$age[df$cheat == 0])
summary(df$age[df$cheat == 1])
```
\begin{itemize}
\item The age of individuals involved in affairs mostly distributed between 22-33.   
\item It is interesting to note that the age distribution of people involved in affairs is almost identical to the age distribution of people not involved in affairs. The average age of people involved in affairs is slightly higher than those who are not. 
\item The overall age distribution of the sample resembles a right-skewed, log-normal distribution.
\end{itemize}

```{r echo=FALSE, fig.cap="(Left) The proportion of cheating individuals distributed over number of years married. (Right) The proportion of individuals with children in the cheating group (cheat=1) and non-cheating group (cheat=0)."}
p3 <- ggplot(data = df, aes(x=yearsmarried, fill = factor(cheat))) +
  geom_histogram(color="#e9ecef", alpha=0.6, position = 'identity', binwidth = 4) +
  labs(fill = "cheat")

p4 <- ggplot(data = df, aes(x=cheat, fill = children)) +
  geom_bar(color="#e9ecef")

grid.arrange(p3, p4, ncol = 2)
```

\begin{itemize}
\item The proportion of individuals involved in affairs increases as number of years married increases.
\item The proportion of individuals involved in affairs most likely have children.
\end{itemize}

```{r echo=FALSE, fig.cap="We use these four histograms to inspect whether the proportion of cheating individuals distributed over other possible predictor variables. There is no evident pattern between affairs and education, occupation and rating. Religiousness stands out as a potentially useful predictor of extramarital affairs."}

p5 <- ggplot(data = df, aes(x=religiousness, fill = cheat)) +
  geom_bar(color="#e9ecef")

p6 <- ggplot(data = df, aes(x=education, fill = cheat)) +
  geom_bar(color="#e9ecef")

p7 <- ggplot(data = df, aes(x=occupation, fill = cheat)) +
  geom_bar(color="#e9ecef")

p8 <- ggplot(data = df, aes(x=rating, fill = cheat)) +
  geom_bar(color="#e9ecef")

grid.arrange(p5, p6, p7, p8, ncol = 2)

```

\begin{itemize}
\item The distribution of individuals involved in affairs by religiousness form an approximate normal distribution.
\item Note that the proportion of individuals that are involved in affairs is significantly lower for the most religious group.
\end{itemize}


# Deeper analysis

```{r, echo=FALSE, fig.cap="Correlation plot of all ordinal variables in the 'affairs' dataset with blue indicating positive correlation and red indicating negative correlation."}
numerical_data <- c("affairs", "age", "yearsmarried", "religiousness", 
                    "education", "occupation", "rating")
dat <- df[,numerical_data]
corrplot(cor(dat), method = 'square', order = 'FPC',  diag = FALSE)
```

The correlation plot suggests that the marriage rating has the greatest negative correlation with affairs. Hence, you are more likely to cheat on your spouse if the marriage rating is low. This makes sense since people cheat when they are unsatisfied with their current partner or they wouldn't cheat.

The next predictor that is most correlated with affairs is years marriaged with positive correlation. The aligns with our insight from plots earlier. A plausible explanation might be as the years of marriage increases, the relationship becomes more boring and people are likely to draw their attention to other potential partners. 

The negative correlation between religiousness and affairs suggests that the more religious you are, the less likely you are going to cheat. A possible reasoning behind this is that oftentimes, cheating is condemned in religion. The correlation of other predictors are too insignificant. 

\newpage

# Classification
Since the frequency of extramarital affairs is split into ranges, this can be considered a multi-class classification problem. If our model can effectively predict the frequency class of affairs, it can also predict whether or not an individual would be involved in an affair (since the frequency would be 0 or greater than 0). Hence, a model which can predict frequency is desirable. We also do not know the shape of the decision boundaries for certain when we have 8 dimensions to consider.

## KNN {-}
The KNN classification algorithm is capable of classifying similar samples together. However, since our data involves categorical features, we cannot use euclidean distance. Hence, we propose to use gower's distance\footnote{Distance between two observations is obtained as a weighted sum of differences for each variable. By default, the weights are all equal to 1. \href{https://www.kaggle.com/ayusov/knn-with-gower-distance?fbclid=IwAR21fUgqyKOthFeJlPp0mNHNU9xErOsQ71OlEubNH2Yutml-5c6An_b2MG0}{Reference: KNN with Gower distance}}, which is a measure of how different two observations are. The smaller the distance, the closer you are and vice-versa. The mode\footnote{ \href{https://stackoverflow.com/questions/2547402/how-to-find-the-statistical-mode?fbclid=IwAR3Ze91ov81mae33CTEfq3HOZGCPTG4dZG9DzPfgEjJjhu7AlUXv_cfPwQI}{Reference: How to find the statistical mode?}} of the neighbouring classes will be used to classify new observations.

```{r echo=FALSE}
# Finds the most common element in x
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Using gower's distance, predict using k-nearest neighbours
#   x: design matrix, size n x p
#   y: response vector, size n
#   x2: new observations to predict, size _ x p
#   k: number of nearest neighbours to consider
knn_w_gower <- function(x,y,x2,k) {
  x_m <- data.matrix(x)
  if (k > nrow(x_m) || k > length(y)) {
    cat("Try again with a value of k <", nrow(x_m) + 1, "\n")
    stop()
  }
  if (nrow(x_m) != length(y)) {
    cat("Design matrix and response vector have mismatched lengths \n")
    stop()
  }
  x2_m <- data.matrix(x2)
  dist <- gower.dist(x_m, x2_m)
  pred <- c()
  for(i in 1:nrow(x2)) {
    dist_order <- order(dist[,i])
    pred <- c(pred, Mode(y[dist_order[1:k]]))
  }
  return(pred)
}
```

```{r tests, include=FALSE}
library(testthat)
test_that("Mode finds the most commonly occuring element of x", {
  expect_equal(Mode(c(0,1,1,1,0)), 1)
  expect_equal(Mode(c(0,1,1,2,1,0)), 1)
  expect_equal(Mode(c("A", "A", "B")), "A")
  expect_equal(Mode(c("A", "B")), "A")
  expect_equal(Mode(c()), c())
})

# Numerical test data
test_x <- data.frame("x1" = c(7,7,3,1), "x2" = c(7,4,4,4))
test_y <- c(0,0,1,1)
test_x2 <- data.frame("x1" = c(3), "x2" = c(7))

# Categorical test data
cat_test_x <- data.frame("x1" = c("no", "yes", "no", "yes", "yes"), 
                         "x2" = factor(c(1,0,1,0,0)),
                         "x3" = c(0,4,0,5,6.5))
cat_test_y <- c(0,1,1,0,0)
cat_test_x2 <- data.frame("x1" = c("yes"), "x2" = c(0), "x3" = c(5.5))
test_that("KNN classifies new data correctly", {
  # when k=3 column 1, 3, and 4 are neighbours
  expect_equal(knn_w_gower(test_x, test_y, test_x2, 3), 1)
  expect_equal(knn_w_gower(cat_test_x, cat_test_y, cat_test_x2, 5), 0)
  # when k=3 column 4, 5, and 2 are neighbours
  expect_equal(knn_w_gower(cat_test_x, cat_test_y, cat_test_x2, 3), 0)
  # when k=3 column 4 and 5 are neighbours
  expect_equal(knn_w_gower(cat_test_x, cat_test_y, cat_test_x2, 2), 0)
  expect_error(knn_w_gower(test_x, test_y, test_x2, 60))
  expect_error(knn_w_gower(test_x, c(1), test_x2, 1))
})
```

```{r echo=FALSE, knn-gower}
# Performs k-fold CV with KNN
# https://ubc-stat.github.io/stat-406/schedule/05-estimating-test-mse.html#16
#   data: contains response in the first column and predictors in the others
#   k: used in KNN to indicate number of nearest neighbours to consider
#   kfolds: number of ways to split the data for train/test
kfold_cv <- function(data, k = 5, kfolds = 10){
  n <- nrow(data)
  set.seed(1234)
  fold.labels <- sample(rep(1:kfolds, length.out = n))
  est_pred_error <- double(kfolds)
  
  for (fold in 1:kfolds) {
    test.rows <- fold.labels == fold
    train <- data[!test.rows,]
    test <- data[test.rows, ]
    y <- train[,1]
    
    predictions <- knn_w_gower(train[,-1], y, test[, -1], k)
    test_responses <- test[,1]
    
    test_errors <- sum(test_responses != predictions)/length(test_responses)
    est_pred_error[fold] <- mean(abs(test_errors))
  }
  mean(est_pred_error)
}


```

```{r echo=FALSE}
# Plot the CV error for different k used in KNN
kfold_plot <- function(data, k){
  kneighbours <- 1:k
  error <- rep(0, k)
  
  for(i in kneighbours){
    error[i] <- kfold_cv(data, k = i, kfolds = 10)
  }

  p <- ggplot(data = data.frame(error), aes(x = kneighbours, y = error)) +
    geom_point() +
    geom_line() + 
    labs(title = "Error rate found through 10-fold CV", y = "Error (% misclassified)", x = "k (# of neighbours in KNN)")
  
  return(list(p, error))
}
```

```{r echo=FALSE}
train <- subset(df, select = -c(cheat))
knn.error <- kfold_plot(train, 20)
knn.error[[1]]
knn.cv <- knn.error[[2]][13]
```
Using the elbow method\footnote{We choose $k$ based on the largest value at which the error rate decreases. \href{https://medium.com/@moussadoumbia_90919/elbow-method-in-supervised-learning-optimal-k-value-99d425f229e7}{Reference: Elbow Method in Supervised ML}}, $k=13$ is the optimal number of nearest neighbors to use with CV score of around 0.2496. One reasoning behind unsatisfactory performance of the model may be due to the unequal distribution of affairs which creates an imbalanced dataset. Only 150 out of the 601 surveyed reported to be in an extramarital affair in the past year. If more cheating individuals are surveyed, we may have more useful observations for making predictions.  

Due to the imbalanced nature of the data, we will use a modern sampling technique to see if we can improve our classification accuracy. First, we will formulate our problem into a binary classification problem such that we will try to predict if an individual is involved in an affair or not. In this way, we can try to model the pattern for people involved in affairs. 

Furthermore, we will use other types of predictive models which can give us an idea of which factors contribute the post to predicting affairs. With KNN, it is unclear which variables had the greatest influence.

# SMOTE Sampling
SMOTE (Synthetic Minority Over-sampling Technique)\footnote{In binary prediction, we oversample the cheating group which is a straightforward usage of the SMOTE function. For multi-class prediction, we perform one vs. all balancing for each nonzero 'affairs' group. \href{https://medium.com/analytics-vidhya/smote-technique-for-unbalanced-data-of-3-classes-in-r-programming-cardiotocography-data-set-474bb5dbf8dd}{Reference: Multi-class SMOTE example}} is an oversampling technique which oversamples from the minority class using nearest neighbours to generate a balanced dataset. We expect the algorithm to perform much better with the newly generated, balanced dataset. 
```{r, echo=FALSE}
predictors <- subset(df, select = -c(affairs))
predictors$gender <- as.numeric(predictors$gender)-1
predictors$children <- as.numeric(predictors$children)-1
tb1 <- table(predictors$cheat)
names(tb1) <- c("Did not cheat", "Did cheat")
knitr::kable(tb1, col.names = c(), caption = "Before SMOTE balancing:") %>% 
  kable_styling(latex_options=c("hold_position"))

newData <- SMOTE(predictors[,1:8], predictors$cheat, K = 5)$data
newData$class <- as.factor(newData$class)
tb2 <- table(newData$class)
names(tb2) <- c("Did not cheat", "Did cheat")
knitr::kable(tb2, col.names = c(), caption = "After SMOTE balancing:") %>% 
  kable_styling(latex_options=c("hold_position"))
```
The new dataset contains 450 observations of class 1 which is 3 times the original number of observations we had before so the dataset is now balanced.

# Random Forests (Binary)
Random Forest is an ensemble classification algorithm which is capable of classifying similar data together. It can handle categorical variables well and has lower computation time than KNN, as we do not need to calculate the distance between observations.

The cross-validation score is about 16.65\% with out-of-bag error of approximately 16\%. So far, we can more accurately determine whether an individual cheats, rather than the individual's frequency of affairs. In the next section, we will try using a random forest model for multi-class classification to compare with our KNN model.   

From the variable importance plot below (Figure 7), we see that rating and religiousness are the best in the sense that they have the highest mean decrease in gini index\footnote{Variables with a higher mean gini decrease lead to tree splits with descendant nodes that are more "pure", where fewer observations are misclassified. Reference: \href{https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm}{Gini importance}}. This aligns with our initial analysis that rating and religiousness would be highly correlated with cheating. Children and gender have the lowest mean decrease in gini index. This conclusion aligns with our initial analysis. We observed an evident pattern and correlation between rating and religiousnes while we did not see any for children and gender.

```{r random forest, include=FALSE}
# Performs k-fold CV on binary data with random forest model
# https://ubc-stat.github.io/stat-406/schedule/05-estimating-test-mse.html#16
kfold_cv_rf_binary <- function(data, kfolds = 10){
  n <- nrow(data)
  set.seed(1234)
  fold.labels <- sample(rep(1:kfolds, length.out = n))
  est_pred_error <- double(kfolds)
  
  for (fold in 1:kfolds) {
    test.rows <- fold.labels == fold
    train <- data[!test.rows,]
    test <- data[test.rows,]
    
    rf <- randomForest(class~., data=train, ntrees=1000)
    predictions <- predict(rf, test)
    test_responses <- test$class
    
    test_errors <- mean(test_responses != predictions)
    est_pred_error[fold] <- mean(abs(test_errors))
  }
  mean(est_pred_error)
}
binary.error <- kfold_cv_rf_binary(newData, 20)
cat(paste0("Error rate from 20-fold CV: ", binary.error))

set.seed(1234)
ntrees <- 1000
rf <- randomForest(class~., data=newData, ntrees=ntrees)
rf
# oob.rf <- predict(rf)
# tab.rf <- table(truth = newData$class, oob = oob.rf)
# knitr::kable(tab.rf)
# 1 - sum(diag(tab.rf)) / sum(tab.rf)
```

```{r echo=FALSE, fig.height = 4, fig.cap="Importance of predictors in the binary random forest model measured by mean decrease in Gini index."}
var.imp <- importance(rf)
var.imp.df <- data.frame(var.imp)
var.imp.df <- tibble::rownames_to_column(var.imp.df, "variable")
colnames(var.imp.df) <- c("variable", "mean_decrease_Gini")
ggplot(data = var.imp.df, 
       aes(x = reorder(variable, mean_decrease_Gini), 
           y = mean_decrease_Gini, 
           main="Variable Importance")) +
  geom_bar(stat = "identity", fill = "#FF6666") +
  coord_flip() + labs(x = "Variable", y = "Mean Decrease in Gini Index")
```

# Random Forests (Multiclass)
We now perform smote oversampling technique on the variable affairs to solve our original imbalanced dataset problem and perform random forest classification to predict the frequency class of affairs.
```{r balancing, echo=FALSE}
predictors <- subset(df, select = -c(cheat))
predictors$gender <- as.numeric(predictors$gender)-1
predictors$children <- as.numeric(predictors$children)-1
table.affaircount <- table(predictors$affairs)
t1 <- t(table.affaircount)
t1 <- rbind(freq=colnames(t1), t1)
rownames(t1) <- list("Frequency of affairs", "# samples")
knitr::kable(t1, col.names = c(), caption = "Before SMOTE balancing:") %>% 
  kable_styling(latex_options=c("hold_position"))

new.data <- predictors[which(predictors$affairs == 0),-1]
new.data$class = 0
for (i in c(1,2,3,7,12)) {
  count.dup <- round((table.affaircount[as.character(0)]-table.affaircount[as.character(i)])/table.affaircount[as.character(i)])
  predictors$affairs.new <- predictors$affairs
  for (j in 1:nrow(predictors)){
    predictors$affairs.new[j] <- ifelse(predictors$affairs.new[j] == i,i,ifelse(predictors$affairs.new[j] != 0, -1, 0))
  }
  predictors.new <- predictors[,-1] 
  smote.result <- SMOTE(predictors.new[,-c(ncol(predictors.new))], predictors.new$affairs.new, dup = count.dup)
  data.result <- smote.result$data
  data.result$class <- as.factor(data.result$class)
  
  oversample <- filter(data.result, data.result$class == i)
  new.data <- rbind(new.data, oversample)
}

new.data$class <- as.factor(new.data$class)
tb2 <- table(new.data$class)[c("0", "1", "2", "3", "7", "12")]
tb2 <- t(tb2)
tb2 <- rbind(freq=colnames(tb2), tb2)
rownames(tb2) <- list("Frequency of affairs", "# samples")
knitr::kable(tb2, col.names = c(), caption = "After SMOTE balancing:") %>% 
  kable_styling(latex_options=c("hold_position"))
```

```{r include=FALSE}
# Performs k-fold CV with multi-class response with random forest model
# https://ubc-stat.github.io/stat-406/schedule/05-estimating-test-mse.html#16
kfold_cv_rf_multinomial <- function(data, kfolds = 10){
  n <- nrow(data)
  set.seed(1234)
  fold.labels <- sample(rep(1:kfolds, length.out = n))
  est_pred_error <- double(kfolds)
  
  for (fold in 1:kfolds) {
    test.rows <- fold.labels == fold
    train <- data[!test.rows,]
    test <- data[test.rows,]
    
    rf <- randomForest(class~., data=train, ntrees=1000)
    predictions <- predict(rf, test)
    test_responses <- test$class
    
    test_errors <- mean(test_responses != predictions)
    est_pred_error[fold] <- mean(abs(test_errors))
  }
  mean(est_pred_error)
}
multi.error <- kfold_cv_rf_multinomial(new.data, 20)
cat(paste0("Error rate from 20-fold CV: ", multi.error))

set.seed(1234)
ntrees <- 1000
rf <- randomForest(class~., data=new.data, ntrees=ntrees)
rf
```

```{r multi-rf, echo=FALSE, fig.height = 4, fig.cap="Importance of predictors in the multi-class random forest model measured by mean decrease in Gini index."}
var.imp <- importance(rf)
var.imp.df <- data.frame(var.imp)
var.imp.df <- tibble::rownames_to_column(var.imp.df, "variable")
colnames(var.imp.df) <- c("variable", "mean_decrease_Gini")
ggplot(data = var.imp.df, 
       aes(x = reorder(variable, mean_decrease_Gini), 
           y = mean_decrease_Gini, 
           main="Variable Importance")) +
  geom_bar(stat = "identity", fill = "#FF6666") +
  coord_flip() + labs(x = "Variable", y = "Mean Decrease in Gini Index")
```

The cross-validation score is about 6.5\% with out-of-bag error of approximately 6.8\%. This is a substantial improvement from the previous KNN algorithm.

Surprisingly, for multiclass classification, the best predictor with the most mean decrease in gini index is education. Hence, we can assume that education is an importance variable in predicting frequency of affairs. 

Our conclusion about rating still holds true for multi-class classification as it did for binary classification. However, religiousness has dropped from being the second most important variable from our binary classification model to being the fifth most important in our multi-class classification model. This suggests that religiousness is only useful in predicting whether an individual has cheated.

# Conclusion 
From our analysis, we have discovered that rating and religiousness are the most important factors in determining whether an individual will be involved in an affair. In addition to these variables, education is highly associated with the frequency of affairs. Gender and whether or not one has children are not particularly important in predicting affairs. 

We can make inferences about why our most important predictors impact the frequency of affairs. Rating was shown to have the greatest negative correlation with number of affairs, which aligns with our results. This suggests that individuals who report less satisfaction with their marriage are more likely to, and if so, more frequently cheat on their spouse. Religiousness has a small negative correlation with number of affairs, so non-religious people simply may be more likely to cheat. The importance of education could be explained if we assume that more academically-inclined individuals have better foresight and can predict the consequences of being involved in an affair.

On the other hand, number of years married has the next greatest positive correlation with number of affairs, but 'yearsmarried' does not have significant predictive power in our random forest models. Besides this discrepancy with 'yearsmarried', the correlation plot gave good indicators of which variables would be important in predicting affairs.

Using the Random Forest algorithm, we were able to build a predictive model with cross-validation score of 16\% for determining whether an individual has been involved in an extramarital affair. When using Random Forest to predict the frequency of affairs, we achieved an error of approximately 6.5\%. Considering we built the model based on 601 samples with smote sampling, the result is notable. 

There is a lot of room for improvement for our model. For instance, if more real data is collected from more individuals, we are certain that we can improve the accuracy of our classification model. We can also try to use deep learning to see if it yields a better model, given that we have enough computational power and data. A caveat of this method would be losing the interpretability of variables which we have with random forests. Moreover, if we are able to collect a balanced sample of data the model may be more accurate compared to our usage of oversampled data produced by SMOTE. We could use a stratified sampling method which ensures that we collect an equal number of each range of frequencies. Since our goal is classification, this will improve predictive performance for the minority classes.


<!-- # Gradient Boosting Machines -->

<!-- ``` {r gbm, message=FALSE} -->
<!-- library(gbm) -->
<!-- # Performs k-fold CV with gradient boosting machine using hinge (huber) loss -->
<!-- # https://ubc-stat.github.io/stat-406/schedule/05-estimating-test-mse.html#16 -->
<!-- #   data: contains response in the last column and predictors in the others -->
<!-- #   kfolds: number of ways to split the data for train/test -->
<!-- kfold_cv_gbm <- function(data, kfolds = 10){ -->
<!--   n <- nrow(data) -->
<!--   set.seed(1234) -->
<!--   fold.labels <- sample(rep(1:kfolds, length.out = n)) -->
<!--   est_pred_error <- double(kfolds) -->

<!--   for (fold in 1:kfolds) { -->
<!--     test.rows <- fold.labels == fold -->
<!--     train <- data[!test.rows,] -->
<!--     test <- data[test.rows, ] -->

<!--     # Number of trees (n.trees) = 100 -->
<!--     # Rate of learning (shrinkage) = 0.1 -->
<!--     # Depth of each tree (interaction.depth) = 1 -->
<!--     model <- gbm(class~., data=train, distribution="huberized") -->
<!--     predictions <- as.numeric(predict(model, test) > 0) -->
<!--     test_responses <- test$class -->
<!--     est_pred_error[fold] <- mean(test_responses != predictions) -->
<!--   } -->
<!--   mean(est_pred_error) -->
<!-- } -->
<!-- ``` -->

<!-- https://stats.stackexchange.com/questions/422458/gbm-how-to-interpret-relative-variable-influence -->

<!-- ``` {r message=FALSE} -->
<!-- gbm.df <- newData -->
<!-- gbm.df$class <- as.integer(gbm.df$class)-1 -->
<!-- kfold_cv_gbm(gbm.df, 20) -->

<!-- set.seed(1234) -->
<!-- model <- gbm(class~., data=gbm.df, distribution="huberized") -->
<!-- var.imp <- summary.gbm(model, plotit=FALSE) -->
<!-- var.imp.df <- data.frame(var.imp[,"var"], var.imp[,"rel.inf"]) -->
<!-- colnames(var.imp.df) <- c("variable", "mean_decrease_Gini") -->
<!-- ggplot(data = var.imp.df,  -->
<!--        aes(x = reorder(variable, mean_decrease_Gini),  -->
<!--            y = mean_decrease_Gini,  -->
<!--            main="Variable Importance")) + -->
<!--   geom_bar(stat = "identity", fill = "#FF6666") + -->
<!--   coord_flip() + labs(x = "Variable", y = "Relative Importance") -->
<!-- ``` -->


<!-- ``` {r xgboost, message=FALSE, include=FALSE} -->
<!-- library(xgboost) -->
<!-- # Seems difficult to explain choice of hyperparameters? -->

<!-- # Performs k-fold CV with XGBoost, with modifications from lecture slides  -->
<!-- # https://ubc-stat.github.io/stat-406/schedule/05-estimating-test-mse.html#16 -->
<!-- #   data: contains response in the last column and predictors in the others -->
<!-- #   kfolds: number of ways to split the data for train/test -->
<!-- kfold_cv_xgboost <- function(data, kfolds = 10){ -->
<!--   n <- nrow(data) -->
<!--   set.seed(1234) -->
<!--   fold.labels <- sample(rep(1:kfolds, length.out = n)) -->
<!--   est_pred_error <- double(kfolds) -->

<!--   for (fold in 1:kfolds) { -->
<!--     test.rows <- fold.labels == fold -->
<!--     train <- data[!test.rows,] -->
<!--     test <- data[test.rows, ] -->
<!--     y <- train[,9] -->

<!--     model <- xgboost(data=data.matrix(train[,1:8]), label = y,  -->
<!--                      objective="binary:logistic", nrounds = 40, -->
<!--                      eval.metric="logloss", colsample_bytree = 0.5, -->
<!--                      eta = 0.1, subsample=0.5, verbose=FALSE) -->
<!--     predictions <- as.numeric(predict(model, data.matrix(test[,1:8])) > 0.5) -->
<!--     test_responses <- test[,9] -->
<!--     est_pred_error[fold] <- mean(test_responses != predictions) -->
<!--   } -->
<!--   mean(est_pred_error) -->
<!-- } -->

<!-- predictors <- df[,2:10] -->
<!-- predictors$cheat <- as.integer(predictors$cheat)-1 -->
<!-- kfold_cv_xgboost(predictors, 10) -->
<!-- ``` -->



